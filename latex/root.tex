\documentclass[12pt]{article}

% Misc. packages
\usepackage{fancyvrb}
\usepackage{url}
\usepackage{hyperref}
\usepackage{authblk}
\usepackage{geometry}
\usepackage{enumerate}

% Math & Symbol packages
\usepackage{mathtools,bm}
\usepackage{amsmath,amsfonts,amssymb}   %% AMS mathematics macros
\usepackage{amsmath}
\usepackage{amssymb}

% Graphics & Float packages
\usepackage{float}
\usepackage{graphicx}
%\usepackage{subfigure}
\usepackage{tikz}
\usepackage{pgfplots}
\pgfplotsset{compat=newest}

% Tikz and pgfplots libraries
\usetikzlibrary{patterns, arrows.meta, calc}
\usepgfplotslibrary{fillbetween}

% Colors
\usepackage{xcolor}
\definecolor{lightblue}{rgb}{0.0,0.5,0.8}
\definecolor{HMSRed}{HTML}{C5112E}  % [197, 17, 46]
\definecolor{MGHBlue}{HTML}{008BB0} % [0, 139, 176]
\definecolor{MGHGrey}{HTML}{626365} % [98, 99, 101]

% Annotation commands
\newcommand{\todo}[1]{{\color{lightblue}\par {[{\bf TO DO: } {\em #1}} ] \\    }}
\newcommand{\addref}[1]{{\color{red}{\bf [REF #1]}}}
\newcommand{\MPKcomment}[1]{{\color{magenta}\par {[{\bf MPK: } { #1}} ] \\    }}
\newcommand{\DCcomment}[1]{{\color{magenta}\par {[{\bf DC: } { #1}} ] \\    }}
\newcommand{\KvAcomment}[1]{{\color{magenta}\par {[{\bf KvA: } { #1}} ] \\    }}

% Document formatting
\linespread{1.4}
\geometry{
a4paper,
total={174mm,257mm},
left=20mm,
top=20mm,
}
\renewcommand{\floatpagefraction}{.8}
\renewcommand\Affilfont{\fontsize{9}{10.8}\itshape}

%~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~%
\title{Solving the dynamic fluence map sequencing problem using piecewise linear leaf position and dose rate functions}
%\title{Dynamic leaf sequencing via trajectory representations of leaf trajectories and dose rate}

\author{Matthew Kelly, Koos van Amerongen, David Craft}
\affil[]{Department of Radiation Oncology, Massachusetts General Hospital, Harvard Medical School}
%% \date{February 13, 2016}  % Comment to use today's date

\begin{document}

\maketitle
\thispagestyle{empty}

\begin{abstract}
  Within the setting of intensity modulated radiation therapy (IMRT) and the fully continuous version of IMRT called
  volumetric modulated radiation therapy (VMAT), we consider the problem of matching a given fluence map $f$ as well as possible in
  limited time $T$ by the use of a multi-leaf collimator (MLC).
  We use linear splines for MLC leaf positions and the dose rate as functions of time, a novel contribution of this work.
  The optimization computes the dose rate and leaf trajectories that best produce
  the target fluence map.
  Computing the dose rate and leaf trajectories is a non-convex optimization problem
  with many local minima.
  In our optimization we use a smooth model of how the leaves block the fluence radiation,
  which helps speed computation and avoid local minima.
  We solve the optimization in two parts:
  an outer optimization loop that optimizes the dose rate pattern over time, and
  an inner optimization loop that, given a fixed dose rate pattern, optimizes the leaf trajectories.
\end{abstract}

\section{Introduction}
The optimal dynamic delivery of a given fluence map by a multi-leaf collimator (MLC) remains a difficult, largely unsolved problem.
The sliding-window leaf-sweep algorithm (SWLS) \cite{leafsweep},
    in which the MLC leaves cross the treatment field in a unidirectional fashion,
    achieves perfect fluence map replication if sufficient time is available \cite{Stein94}.
However, the SWLS algorithm is not in general efficient with respect to the required delivery time.
Time is an important aspect of VMAT and IMRT treatment plans, for several reasons:
\begin{enumerate}[i)]
  \item The effect of patient movement on delivery inaccuracy increases in the time the patient is exposed to radiation.
  \item Shorter treatments allow the treatment facility to help more patients on a given set of radiation therapy machines,
        which is particularly relevant to third-world countries as these machines are expensive.
  \item In general, there is a trade-off between dose quality and delivery time, and given how widespread the use of radiation therapy is in treating cancer, it makes sense to put in effort to assure that we are on the Pareto optimal frontier regarding these two objectives.

\end{enumerate}
Several studies have investigated the trade-off between treatment time and plan quality \cite{tradeoffSalari,tradeoffMCO,tradeoffCraft}.
\cite{balvertcraft} were the first to include treatment time directly in a dynamic leaf sequencing step of the treatment plan optimization.
They constructed the trade-off curve between delivery time and fluence map matching accuracy by optimizing leaf trajectories and dose rate patterns for a sequence of delivery times.
% for several leaf trajectories independently
For a given fluence map and fixed delivery time, the challenge of optimizing the leaf trajectories and dose rate versus time so that the given fluence map is matched as accurately as possible, subject to machine restrictions, presents a high dimensional nonconvex optimization problem.
The nonconvexity of the fluence map matching problem leads to a large number of local minima.
For a thorough introduction to the complexities of dynamic fluence map delivery (which generally arises in the context of dynamic IMRT and VMAT),
 see \cite{balvertcraft} and \cite{unkvmatreview}.

\section{Model}
\label{sec:model}

Our starting point is a fluence map $m$
that has been optimized, along with additional fluence maps located around the patient, to collectively yield a dose distribution optimized for the particular patient's geometry (location of tumor and all nearby organs) and dose prescription. We do not model this aspect of the problem and simply assume that the optimal fluence maps are given. The algorithms set forth in this paper determine how to construct a single given fluence map by moving the leaves of the MLC across the field, while varying the dose rate.
Our optimization allows the leaves to move back and forth, a requirement for achieving optimal motions, as shown in the Appendix of \cite{balvertcraft}.
Moreover, we allow the leaves of every pair to start and end separately and not necessarily at the bounds of the treatment field, as these restrictions can also be suboptimal \cite{thesisKvA}.
%Note: it is easy to include this restriction, e.g. to smooth transitions between maps.

We assume the fluence map $m$ is given as a matrix where the rows correspond to the individual left and right leaf pairs, and the columns are the discretely optimized fluence bixels across the field, which can be as finely discretized as one wishes. Typical length scales are on the order of 0.5 cm for both the row height of the MLC leaves and the across-the-row discretization.

Let $x^i_L(t)$ and $x^i_R(t)$ denote the leaf position of the $i$th left and right leaves respectively, at time $t$.
Our framework puts the dose rate optimization in an outer loop. Once the outer loop sets a dose rate over time profile, the leaf rows can be optimized independently (neglecting the small coupling terms created by the tongue-and-groove mechanism on the real machine, see \cite{unkvmatreview}), so for the remainder of the algorithm development, we consider only a single leaf row.

For the remainder of this section we will consider a single row of the fluence map $m$, and thus a single pair of leaves (left and right). Let $f(x)$ be the target fluence that should be delivered for that row.

% We typically think of $f(x)$ as a continuous function of $x$, although it if is computed directly from the target fluence map $m$ then $f$ will be piecewise constant. It is reasonable to model $f(x)$ as continuous because the fluence map $m$ is really just a discrete approximation of a smooth function.

We assume the total allowed treatment delivery time $T$ is given. Our goal is then to compute leaf trajectories $x_L(t)$ and $x_R(t)$ as well as a dose rate $d(t)$ to recreate the fluence row $f(x)$ as best as possible, while accounting for maximum leaf speed, maximum dose rate, and collision constraints.

The fluence achieved at each position is $g(x)$, which is the time-integral of the dose rate for the times that position is exposed to the radiation source.
The time domain $\mathcal{T}(x)$ is the set of times (in general a disconnected set) when the position $x$ is not blocked by either of the leaves, i.e.,
$\mathcal{T}(x)$ is the set of all times $t$ such that $x_L(t) \le x \leq x_R(t)$,
as illustrated by Figure \ref{fig:administeredDose} .

\begin{equation}
g(x) = \int_{\mathcal{T}(x)} d(t) dt
\label{eqn:deliveredFluenceDose}
\end{equation}

Our goal is to find the leaf trajectories $x_L(t)$ and $x_R(t)$ and dose rate pattern $d(t)$
that minimize the squared integral error between the target fluence $f(x)$ and the delivered fluence $g(x)$:

\begin{equation}
\underset{d(t), \, x_L(t), \, x_R(t)}{\operatorname{argmin}}
\int_X \bigg(f(x) - g(x)\bigg)^2 dx .
\label{eqn:fluenceMapOptimization}
\end{equation}

\input{fig/administeredDose}


\section{Method}

In this section we describe the method that we use to convert the mathematical optimization problem from Section \ref{sec:model} into a nonlinear program (NLP) that can be solved using standard NLP solvers such as FMINCON \cite{MatlabOptimizationToolbox2014}, SNOPT \cite{Snopt7}, or IPOPT \cite{Wachter2006}.

The first step in this process is to select a discrete representation for the leaf and dose rate trajectories. Here we will use piecewise linear functions. The second step is to compute the integrals in the objective function using methods that are smooth and consistent, a critical step for obtaining good results from the NLP solver.

\subsection{Spline Representation}

There are three continuous functions that must be computed by the optimization: the position of the left and right leaves, $x_L(t)$ and $x_R(t)$, and the dose rate $d(t)$. We use piecewise linear functions (linear splines) to represent each function. A linear spline is fully defined by its value at the knot points $t_k$: $x_{L,k}$, $x_{R,k}$, and $d_k$. For simplicity we choose to use the same set of knot points for all three splines. An example of a linear spline is shown in Figure \ref{fig:linearSpline}.

\begin{figure}
  \centering
  \includegraphics{fig/linearSpline.pdf}
  \caption{Linear Spline. We represent the dose rate and leaf position trajectories as linear splines. A linear spline is fully defined by its values at the knot points. }
  \label{fig:linearSpline}
\end{figure}

\subsection{Integral Computation with Blocking Function $k()$}
\label{sec:IntegralComputationWithBlockingFunction}

One critical step in evaluating the objective function (Equation \ref{eqn:fluenceMapOptimization}) is to compute an approximation of the delivered fluence $g(x)$, given in Equation \ref{eqn:deliveredFluenceDose}.

There are two numerical issues with computing this integral directly: 
1) computing the domain $\mathcal{T}$ requires a root solve (or inverting the leaf trajectories), and 2) the domain of $\mathcal{T}$ can change from being simply connected to discontinuous during an optimization. Both of these issues would likely cause convergence failures in the NLP solver, in part by causing a change in the sparsity pattern of the gradient
(\textit{e.g.} $\tfrac{\partial g}{\partial x_L})$)
between successive iterations.

Our solution is to rewrite the integral using a blocking function $k(t,x)$, which has a value of one when the leaves at time $t$ are passing radiation at location $x$ and zero when the leaves are blocking radiation. This allows us to rewrite the integral using the constant bounds $[0, T]$:

\begin{equation}
  g(x) = \int_0^T \! k(t, x) \cdot d(t) \, dt
  \label{eqn:fluenceDoseSimpleBounds}
\end{equation}

We now have a standard scalar integral and we can use any quadrature method to evaluate (\ref{eqn:fluenceDoseSimpleBounds}).
In our case we use the midpoint (rectangle) quadrature rule.

As just defined, our fluence blocking function $k(t,x)$
would also have a discontinuous gradient, which would cause problems in the optimization.
Therefore, we use an exponential sigmoid function to approximate the step function
$s(x, \alpha) = (1 + e^{-x \alpha})^{-1}$, where $\alpha$ is the smoothing parameter. A smaller smoothing parameter will provide a more accurate model, while a larger smoothing parameter will lead to faster optimization.

We can then combine the smoothing function for each leaf to get the combined blocking function:

\begin{equation}
  k(t, x) \approx \sqrt{s\big(x_R(t) -x, \, \alpha\big) \; \cdot \; s\big(x -x_L(t), \, \alpha\big)}
  \label{eqn:blockingFunction}
\end{equation}


In practice it is useful to define the $\alpha$ parameter in terms of 
a smoothing distance $\Delta x$ and 
the fraction $\gamma$ that the blocking function changed over that distance.
For example, $\Delta x = 0.05$ cm and $\gamma = 0.98$ means that 
the blocking function changes from $0.01$ to $0.99$ over a distance of $0.05$ cm.


\begin{equation}
  \alpha = \frac{-2}{\Delta x} \; \ln \! \left( \frac{1 - \gamma}{1 + \gamma} \right)
  \label{eqn:SmoothingDistanceParameter}
\end{equation}

Figure \ref{fig:visualizeExponentialSmoothing} shows three values of the smoothing parameter for the blocking function $k(t, x)$, where $x_R = 1$ and $x_L = -1$, and compares the function to the case without smoothing.

\begin{figure}
  \centering
  \includegraphics[width=\textwidth]{fig/FIG_visualize_exponential_smoothing.pdf}
  \caption{Visualization of smoothing parameters in the blocking function (\ref{eqn:blockingFunction}. The right and left leaves are at $x_R = 1 cm$ and $x_L = -1 cm$ respectively. The solid black line shows the case without smoothing, and the remaining lines show light smoothing ($\Delta = 0.05$ cm), moderate smoothing ($\Delta = 0.2$ cm), and heavy smoothing($\Delta = 0.5$ cm). In each of these three cases we use a value of $\gamma = 0.95$.}
  \label{fig:visualizeExponentialSmoothing}
\end{figure}


\subsection{Objective Function}

The objective function for the inner optimization (computing leaf trajectories)
is the integral of the error-squared between the desired fluence $f(x)$ and the fluence that
is delivered by the current set of trajectories, $g(x)$.
\begin{equation}
  J = \int_{x_\text{min}}^{x_\text{max}} \! \bigg( f(x) - g(x) \bigg)^2 \,dx
  \label{eqn:continuousFittingObjective}
\end{equation}

In practice we can only compute the fluence profile at a finite number of points. We will break the domain $[x_\text{min}, x_\text{max}]$ into $N_\text{fit}$ equal-width segments,
and evaluate the fluence target and delivered fluence at the midpoint $x_k$ of each segment.

\begin{equation}
  J \approx \frac{x_\text{max} - x_\text{min}}{N_\text{fit}}
  \sum_{k = 1}^{N_\text{fit}} \! \bigg( f(x_k) - g(x_k) \bigg)^2
  \label{eqn:discreteFittingObjective}
\end{equation}

\subsection{Computing Leaf Trajectories as a Nonlinear Program}
\label{sec:LeafTrajectoryAsNLP}

The inner optimization loop computes the leaf trajectories $x_L(t)$ and $x_R(t)$
that minimize the objective function (\ref{eqn:discreteFittingObjective})
and satisfy the position and velocity constraints given below.
This optimization is solved as a nonlinear program.

We model the leaf trajectories as piecewise-linear functions of time,
where the decision variables in the optimization are the position of each leaf
at the knot points in the spline: $x_{L, k}$, $x_{L, k}$, as shown in Figure \ref{fig:linearSpline}.

We can compute the position on each segment by linear interpolation between the knot points.

The position of each leaf is linear over a single segment, thus the velocity of the leaf on that segment is constant,
with a change in value at each knot point.
The velocity for each segment is:

\begin{equation}
  \dot{x}_{L, k} = \frac{x_{L, k+1} - x_{L, k}}{h_k}
  \quad \quad
  \dot{x}_{R, k} = \frac{x_{R, k+1} - x_{R, k}}{h_k}
\end{equation}
\noindent where $h_k$ is the distance between knot point $k$ and $k+1$ (we use equal spacing for all knot points).

The limits on leaf position can be implemented as a combination of
constant bounds and linear inequality constraints:

\begin{equation}
  x_\text{min} \leq x_{L, k}
  \quad \quad
  x_{R, k} \leq x_\text{max}
  \quad \quad
  x_{L, k} \leq x_{R, k}
  \quad \quad
  \forall k
  \label{eqn:PositionLimits}
\end{equation}

The limits on velocity can be written as linear inequality constraints:

\begin{equation}
  -v_\text{max} \leq \dot{x}_{L, k} \leq v_\text{max}
  \quad \quad
  -v_\text{max} \leq \dot{x}_{R, k} \leq v_\text{max}
  \quad \quad \forall k
  \label{eqn:VelocityLimits}
\end{equation}

At this point we can compute the piecewise-linear position trajectories and the
piecewise-constant velocity trajectories, and enforce limits on them inside the non-linear program.
The final step is to compute the objective function for the candidate trajectories,
which is done as described in Section \S~\ref{sec:IntegralComputationWithBlockingFunction}.

\subsection{Iterative refinement of smoothing parameter}

In practice, the leaf trajectory optimization runs well 
when the smoothing distance $\gamma$ is large.
As the smoothing becomes smaller, the optimization becomes more difficult to solve,
but the model is more accurate.

We can use these properties to our advantage by iteratively solving the optimization problem.
On the first iteration we use a large value for the smoothing parameter,
which will quickly find a good approximation of the solution.
On subsequent iterations we use the solution from the previous optimization as the initial guess,
and then reduce the smoothing parameter until we achieve the desired model accuracy.

This process is effective at avoiding local minima because
the optimization with heavy smoothing inherently focuses on the global aspects of the problem.
Subsequent optimizations are similar, so the previous solution is an excellent guess,
and the optimization is able to simply refine that solution for the more accurate model.

\todo{Talk about measuring fitting using both smooth and "exact" fluence calculation.}

\section{Results}

\subsection{Smoothing Parameter iteration schedule}

\begin{figure}
  \centering
  \includegraphics[width=\textwidth]{fig/FIG_smoothingParamSweep_pareto.pdf}
  \caption{TODO:}
  \label{fig:smoothingParamSweep_pareto}
\end{figure}


\subsection{Leaf trajectory plots for two examples}


\begin{figure}
  \centering
  \includegraphics[width=\textwidth]{fig/FIG_smoothingParamSweep_unimodalTraj.pdf}
  \caption{TODO:}
  \label{fig:smoothingParamSweep_unimodalTraj}
\end{figure}


\begin{figure}
  \centering
  \includegraphics[width=\textwidth]{fig/FIG_smoothingParamSweep_bimodalTraj.pdf}
  \caption{TODO:}
  \label{fig:smoothingParamSweep_bimodalTraj}
\end{figure}


\section{Discussion and conclusions}

\subsection{Choice of smoothing parameter}
- related to how close (on average) the leaves are apart. If far apart, then smoothing is less important. If very close, then smoothing terms dominate.

\subsection{Effect of smoothing on convergence and accuracy}

if heavy smoothing, then inaccurate model

if light smoothing, then gradients are bad and optimization gets stuck

can benchmark against "truth" model easily during the optimization.

\subsection{How long should the duration of the trajectory be?}

\subsection{How to optimize the dose-rate trajectory?}

\subsection{Why first-order splines to represent trajectories?}
\label{sec:WhyUseLinearSplines}

In this section we informally discuss some of the design choices that were made when creating this
trajectory-based method for solving leaf and dose rate trajectories for fluence mapping.

\todo{This section should be edited to reduce length and needs some detailed citations.}

There are many ways to represent trajectories, and nearly all of them have associated transcription (optimization) methods.
In general there is one major trade-off:
use a larger number of low-order segments or
use a smaller number of high-order segments.

Selecting the correct method order typically comes down to problem specifics.
High-order methods are best when the system model is good and high accuracy is important.
The accuracy of these methods relies on the underlying problem being smooth over each
mesh interval, with few places where path constraints serve to shape the trajectory.
Low-order methods are best when the trajectory shape is dominated by path constraints and
high accuracy is not critical.
\todo{Cite my tutorial paper? Check if I discuss this in detail.
Also see if it is discussed in the reviews by Rao or Betts.}

Although our specific problem does not have path constraints, it does have a highly nonlinear objective function.
The smooth leaf-blocking model causes a strong nonlinearity in the objective function,
which would make careful mesh refinement necessary if high-order methods were used.
\todo{Cite GPOPS-II paper? Or perhaps Rao or Betts tutorial paper.}
We can avoid the need for careful mesh refinement by simply using a low-order model,
which also makes it easier to precisely handle the velocity and position limits on the leaf trajectories.

We did a few brief checks, comparing a few different schemes using cubic splines and compared them
to the linear spline presented in this paper. Although both methods worked, the linear spline methods
were much faster and were able to provide an good fit to the desired fluence profile.
One possible reason for the speed increase is that a set of three linear segments have less
coupling terms than a cubic spline fitting the same trajectory domain. The resulting sparsity in the
jacobian (derivative of the objective function) helps optimization. \cite{Betts2010}

The major drawback of a linear spline for leaf trajectories is that the resulting trajectory tends
to be less smooth, with a step change in velocity between each segment. This effect can be minimized
by using a large number of linear segments. In some cases this can lead to a slight numerical
instability, which is easily addressed by adding a small regularization term to the optimization,
minimizing the integral of the velocity-squared along the trajectory.


\bibliographystyle{unsrt}
\bibliography{all}

\end{document}
